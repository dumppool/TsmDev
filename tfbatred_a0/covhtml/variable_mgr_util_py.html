


<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    
    
    <meta http-equiv="X-UA-Compatible" content="IE=emulateIE7" />
    <title>Coverage for variable_mgr_util.py: 39%</title>
    <link rel="stylesheet" href="style.css" type="text/css">
    
    <script type="text/javascript" src="jquery.min.js"></script>
    <script type="text/javascript" src="jquery.hotkeys.js"></script>
    <script type="text/javascript" src="jquery.isonscreen.js"></script>
    <script type="text/javascript" src="coverage_html.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(coverage.pyfile_ready);
    </script>
</head>
<body class="pyfile">

<div id="header">
    <div class="content">
        <h1>Coverage for <b>variable_mgr_util.py</b> :
            <span class="pc_cov">39%</span>
        </h1>

        <img id="keyboard_icon" src="keybd_closed.png" alt="Show keyboard shortcuts" />

        <h2 class="stats">
            192 statements &nbsp;
            <span class="run hide_run shortkey_r button_toggle_run">74 run</span>
            <span class="mis shortkey_m button_toggle_mis">118 missing</span>
            <span class="exc shortkey_x button_toggle_exc">0 excluded</span>

            
        </h2>
    </div>
</div>

<div class="help_panel">
    <img id="panel_icon" src="keybd_open.png" alt="Hide keyboard shortcuts" />
    <p class="legend">Hot-keys on this page</p>
    <div>
    <p class="keyhelp">
        <span class="key">r</span>
        <span class="key">m</span>
        <span class="key">x</span>
        <span class="key">p</span> &nbsp; toggle line displays
    </p>
    <p class="keyhelp">
        <span class="key">j</span>
        <span class="key">k</span> &nbsp; next/prev highlighted chunk
    </p>
    <p class="keyhelp">
        <span class="key">0</span> &nbsp; (zero) top of page
    </p>
    <p class="keyhelp">
        <span class="key">1</span> &nbsp; (one) first highlighted chunk
    </p>
    </div>
</div>

<div id="source">
    <table>
        <tr>
            <td class="linenos">
<p id="n1" class="pln"><a href="#n1">1</a></p>
<p id="n2" class="pln"><a href="#n2">2</a></p>
<p id="n3" class="pln"><a href="#n3">3</a></p>
<p id="n4" class="pln"><a href="#n4">4</a></p>
<p id="n5" class="pln"><a href="#n5">5</a></p>
<p id="n6" class="pln"><a href="#n6">6</a></p>
<p id="n7" class="pln"><a href="#n7">7</a></p>
<p id="n8" class="pln"><a href="#n8">8</a></p>
<p id="n9" class="pln"><a href="#n9">9</a></p>
<p id="n10" class="pln"><a href="#n10">10</a></p>
<p id="n11" class="pln"><a href="#n11">11</a></p>
<p id="n12" class="pln"><a href="#n12">12</a></p>
<p id="n13" class="pln"><a href="#n13">13</a></p>
<p id="n14" class="pln"><a href="#n14">14</a></p>
<p id="n15" class="stm run hide_run"><a href="#n15">15</a></p>
<p id="n16" class="pln"><a href="#n16">16</a></p>
<p id="n17" class="stm run hide_run"><a href="#n17">17</a></p>
<p id="n18" class="pln"><a href="#n18">18</a></p>
<p id="n19" class="stm run hide_run"><a href="#n19">19</a></p>
<p id="n20" class="stm run hide_run"><a href="#n20">20</a></p>
<p id="n21" class="pln"><a href="#n21">21</a></p>
<p id="n22" class="stm run hide_run"><a href="#n22">22</a></p>
<p id="n23" class="pln"><a href="#n23">23</a></p>
<p id="n24" class="stm run hide_run"><a href="#n24">24</a></p>
<p id="n25" class="stm run hide_run"><a href="#n25">25</a></p>
<p id="n26" class="pln"><a href="#n26">26</a></p>
<p id="n27" class="stm run hide_run"><a href="#n27">27</a></p>
<p id="n28" class="pln"><a href="#n28">28</a></p>
<p id="n29" class="stm run hide_run"><a href="#n29">29</a></p>
<p id="n30" class="pln"><a href="#n30">30</a></p>
<p id="n31" class="pln"><a href="#n31">31</a></p>
<p id="n32" class="pln"><a href="#n32">32</a></p>
<p id="n33" class="pln"><a href="#n33">33</a></p>
<p id="n34" class="pln"><a href="#n34">34</a></p>
<p id="n35" class="pln"><a href="#n35">35</a></p>
<p id="n36" class="pln"><a href="#n36">36</a></p>
<p id="n37" class="pln"><a href="#n37">37</a></p>
<p id="n38" class="pln"><a href="#n38">38</a></p>
<p id="n39" class="pln"><a href="#n39">39</a></p>
<p id="n40" class="pln"><a href="#n40">40</a></p>
<p id="n41" class="pln"><a href="#n41">41</a></p>
<p id="n42" class="pln"><a href="#n42">42</a></p>
<p id="n43" class="pln"><a href="#n43">43</a></p>
<p id="n44" class="pln"><a href="#n44">44</a></p>
<p id="n45" class="pln"><a href="#n45">45</a></p>
<p id="n46" class="pln"><a href="#n46">46</a></p>
<p id="n47" class="pln"><a href="#n47">47</a></p>
<p id="n48" class="pln"><a href="#n48">48</a></p>
<p id="n49" class="stm run hide_run"><a href="#n49">49</a></p>
<p id="n50" class="pln"><a href="#n50">50</a></p>
<p id="n51" class="pln"><a href="#n51">51</a></p>
<p id="n52" class="pln"><a href="#n52">52</a></p>
<p id="n53" class="pln"><a href="#n53">53</a></p>
<p id="n54" class="pln"><a href="#n54">54</a></p>
<p id="n55" class="pln"><a href="#n55">55</a></p>
<p id="n56" class="pln"><a href="#n56">56</a></p>
<p id="n57" class="pln"><a href="#n57">57</a></p>
<p id="n58" class="pln"><a href="#n58">58</a></p>
<p id="n59" class="pln"><a href="#n59">59</a></p>
<p id="n60" class="pln"><a href="#n60">60</a></p>
<p id="n61" class="pln"><a href="#n61">61</a></p>
<p id="n62" class="pln"><a href="#n62">62</a></p>
<p id="n63" class="pln"><a href="#n63">63</a></p>
<p id="n64" class="pln"><a href="#n64">64</a></p>
<p id="n65" class="pln"><a href="#n65">65</a></p>
<p id="n66" class="pln"><a href="#n66">66</a></p>
<p id="n67" class="pln"><a href="#n67">67</a></p>
<p id="n68" class="pln"><a href="#n68">68</a></p>
<p id="n69" class="pln"><a href="#n69">69</a></p>
<p id="n70" class="pln"><a href="#n70">70</a></p>
<p id="n71" class="pln"><a href="#n71">71</a></p>
<p id="n72" class="pln"><a href="#n72">72</a></p>
<p id="n73" class="pln"><a href="#n73">73</a></p>
<p id="n74" class="pln"><a href="#n74">74</a></p>
<p id="n75" class="stm mis"><a href="#n75">75</a></p>
<p id="n76" class="stm mis"><a href="#n76">76</a></p>
<p id="n77" class="pln"><a href="#n77">77</a></p>
<p id="n78" class="stm mis"><a href="#n78">78</a></p>
<p id="n79" class="stm mis"><a href="#n79">79</a></p>
<p id="n80" class="pln"><a href="#n80">80</a></p>
<p id="n81" class="pln"><a href="#n81">81</a></p>
<p id="n82" class="pln"><a href="#n82">82</a></p>
<p id="n83" class="pln"><a href="#n83">83</a></p>
<p id="n84" class="stm mis"><a href="#n84">84</a></p>
<p id="n85" class="pln"><a href="#n85">85</a></p>
<p id="n86" class="pln"><a href="#n86">86</a></p>
<p id="n87" class="pln"><a href="#n87">87</a></p>
<p id="n88" class="pln"><a href="#n88">88</a></p>
<p id="n89" class="stm run hide_run"><a href="#n89">89</a></p>
<p id="n90" class="pln"><a href="#n90">90</a></p>
<p id="n91" class="pln"><a href="#n91">91</a></p>
<p id="n92" class="pln"><a href="#n92">92</a></p>
<p id="n93" class="pln"><a href="#n93">93</a></p>
<p id="n94" class="pln"><a href="#n94">94</a></p>
<p id="n95" class="pln"><a href="#n95">95</a></p>
<p id="n96" class="pln"><a href="#n96">96</a></p>
<p id="n97" class="pln"><a href="#n97">97</a></p>
<p id="n98" class="pln"><a href="#n98">98</a></p>
<p id="n99" class="pln"><a href="#n99">99</a></p>
<p id="n100" class="pln"><a href="#n100">100</a></p>
<p id="n101" class="pln"><a href="#n101">101</a></p>
<p id="n102" class="pln"><a href="#n102">102</a></p>
<p id="n103" class="stm run hide_run"><a href="#n103">103</a></p>
<p id="n104" class="stm run hide_run"><a href="#n104">104</a></p>
<p id="n105" class="stm run hide_run"><a href="#n105">105</a></p>
<p id="n106" class="stm run hide_run"><a href="#n106">106</a></p>
<p id="n107" class="stm run hide_run"><a href="#n107">107</a></p>
<p id="n108" class="pln"><a href="#n108">108</a></p>
<p id="n109" class="stm run hide_run"><a href="#n109">109</a></p>
<p id="n110" class="stm run hide_run"><a href="#n110">110</a></p>
<p id="n111" class="pln"><a href="#n111">111</a></p>
<p id="n112" class="pln"><a href="#n112">112</a></p>
<p id="n113" class="pln"><a href="#n113">113</a></p>
<p id="n114" class="stm mis"><a href="#n114">114</a></p>
<p id="n115" class="pln"><a href="#n115">115</a></p>
<p id="n116" class="stm mis"><a href="#n116">116</a></p>
<p id="n117" class="pln"><a href="#n117">117</a></p>
<p id="n118" class="pln"><a href="#n118">118</a></p>
<p id="n119" class="pln"><a href="#n119">119</a></p>
<p id="n120" class="pln"><a href="#n120">120</a></p>
<p id="n121" class="pln"><a href="#n121">121</a></p>
<p id="n122" class="stm mis"><a href="#n122">122</a></p>
<p id="n123" class="pln"><a href="#n123">123</a></p>
<p id="n124" class="stm mis"><a href="#n124">124</a></p>
<p id="n125" class="pln"><a href="#n125">125</a></p>
<p id="n126" class="pln"><a href="#n126">126</a></p>
<p id="n127" class="pln"><a href="#n127">127</a></p>
<p id="n128" class="pln"><a href="#n128">128</a></p>
<p id="n129" class="pln"><a href="#n129">129</a></p>
<p id="n130" class="stm mis"><a href="#n130">130</a></p>
<p id="n131" class="stm mis"><a href="#n131">131</a></p>
<p id="n132" class="pln"><a href="#n132">132</a></p>
<p id="n133" class="pln"><a href="#n133">133</a></p>
<p id="n134" class="pln"><a href="#n134">134</a></p>
<p id="n135" class="pln"><a href="#n135">135</a></p>
<p id="n136" class="stm mis"><a href="#n136">136</a></p>
<p id="n137" class="pln"><a href="#n137">137</a></p>
<p id="n138" class="pln"><a href="#n138">138</a></p>
<p id="n139" class="pln"><a href="#n139">139</a></p>
<p id="n140" class="stm run hide_run"><a href="#n140">140</a></p>
<p id="n141" class="pln"><a href="#n141">141</a></p>
<p id="n142" class="pln"><a href="#n142">142</a></p>
<p id="n143" class="pln"><a href="#n143">143</a></p>
<p id="n144" class="pln"><a href="#n144">144</a></p>
<p id="n145" class="pln"><a href="#n145">145</a></p>
<p id="n146" class="pln"><a href="#n146">146</a></p>
<p id="n147" class="pln"><a href="#n147">147</a></p>
<p id="n148" class="stm run hide_run"><a href="#n148">148</a></p>
<p id="n149" class="pln"><a href="#n149">149</a></p>
<p id="n150" class="stm mis"><a href="#n150">150</a></p>
<p id="n151" class="stm mis"><a href="#n151">151</a></p>
<p id="n152" class="stm mis"><a href="#n152">152</a></p>
<p id="n153" class="stm mis"><a href="#n153">153</a></p>
<p id="n154" class="pln"><a href="#n154">154</a></p>
<p id="n155" class="stm run hide_run"><a href="#n155">155</a></p>
<p id="n156" class="stm mis"><a href="#n156">156</a></p>
<p id="n157" class="stm mis"><a href="#n157">157</a></p>
<p id="n158" class="stm mis"><a href="#n158">158</a></p>
<p id="n159" class="pln"><a href="#n159">159</a></p>
<p id="n160" class="stm mis"><a href="#n160">160</a></p>
<p id="n161" class="stm mis"><a href="#n161">161</a></p>
<p id="n162" class="stm mis"><a href="#n162">162</a></p>
<p id="n163" class="pln"><a href="#n163">163</a></p>
<p id="n164" class="stm mis"><a href="#n164">164</a></p>
<p id="n165" class="stm mis"><a href="#n165">165</a></p>
<p id="n166" class="stm mis"><a href="#n166">166</a></p>
<p id="n167" class="pln"><a href="#n167">167</a></p>
<p id="n168" class="pln"><a href="#n168">168</a></p>
<p id="n169" class="pln"><a href="#n169">169</a></p>
<p id="n170" class="pln"><a href="#n170">170</a></p>
<p id="n171" class="stm run hide_run"><a href="#n171">171</a></p>
<p id="n172" class="pln"><a href="#n172">172</a></p>
<p id="n173" class="pln"><a href="#n173">173</a></p>
<p id="n174" class="pln"><a href="#n174">174</a></p>
<p id="n175" class="pln"><a href="#n175">175</a></p>
<p id="n176" class="stm run hide_run"><a href="#n176">176</a></p>
<p id="n177" class="stm mis"><a href="#n177">177</a></p>
<p id="n178" class="stm mis"><a href="#n178">178</a></p>
<p id="n179" class="pln"><a href="#n179">179</a></p>
<p id="n180" class="stm mis"><a href="#n180">180</a></p>
<p id="n181" class="stm mis"><a href="#n181">181</a></p>
<p id="n182" class="stm mis"><a href="#n182">182</a></p>
<p id="n183" class="stm mis"><a href="#n183">183</a></p>
<p id="n184" class="pln"><a href="#n184">184</a></p>
<p id="n185" class="stm mis"><a href="#n185">185</a></p>
<p id="n186" class="stm mis"><a href="#n186">186</a></p>
<p id="n187" class="stm mis"><a href="#n187">187</a></p>
<p id="n188" class="stm mis"><a href="#n188">188</a></p>
<p id="n189" class="stm mis"><a href="#n189">189</a></p>
<p id="n190" class="pln"><a href="#n190">190</a></p>
<p id="n191" class="pln"><a href="#n191">191</a></p>
<p id="n192" class="stm run hide_run"><a href="#n192">192</a></p>
<p id="n193" class="pln"><a href="#n193">193</a></p>
<p id="n194" class="pln"><a href="#n194">194</a></p>
<p id="n195" class="stm run hide_run"><a href="#n195">195</a></p>
<p id="n196" class="pln"><a href="#n196">196</a></p>
<p id="n197" class="pln"><a href="#n197">197</a></p>
<p id="n198" class="pln"><a href="#n198">198</a></p>
<p id="n199" class="pln"><a href="#n199">199</a></p>
<p id="n200" class="pln"><a href="#n200">200</a></p>
<p id="n201" class="pln"><a href="#n201">201</a></p>
<p id="n202" class="pln"><a href="#n202">202</a></p>
<p id="n203" class="stm run hide_run"><a href="#n203">203</a></p>
<p id="n204" class="stm run hide_run"><a href="#n204">204</a></p>
<p id="n205" class="stm run hide_run"><a href="#n205">205</a></p>
<p id="n206" class="pln"><a href="#n206">206</a></p>
<p id="n207" class="stm run hide_run"><a href="#n207">207</a></p>
<p id="n208" class="stm run hide_run"><a href="#n208">208</a></p>
<p id="n209" class="stm mis"><a href="#n209">209</a></p>
<p id="n210" class="stm run hide_run"><a href="#n210">210</a></p>
<p id="n211" class="stm run hide_run"><a href="#n211">211</a></p>
<p id="n212" class="pln"><a href="#n212">212</a></p>
<p id="n213" class="stm run hide_run"><a href="#n213">213</a></p>
<p id="n214" class="stm run hide_run"><a href="#n214">214</a></p>
<p id="n215" class="stm run hide_run"><a href="#n215">215</a></p>
<p id="n216" class="stm run hide_run"><a href="#n216">216</a></p>
<p id="n217" class="pln"><a href="#n217">217</a></p>
<p id="n218" class="stm run hide_run"><a href="#n218">218</a></p>
<p id="n219" class="pln"><a href="#n219">219</a></p>
<p id="n220" class="pln"><a href="#n220">220</a></p>
<p id="n221" class="stm run hide_run"><a href="#n221">221</a></p>
<p id="n222" class="pln"><a href="#n222">222</a></p>
<p id="n223" class="pln"><a href="#n223">223</a></p>
<p id="n224" class="pln"><a href="#n224">224</a></p>
<p id="n225" class="pln"><a href="#n225">225</a></p>
<p id="n226" class="pln"><a href="#n226">226</a></p>
<p id="n227" class="pln"><a href="#n227">227</a></p>
<p id="n228" class="pln"><a href="#n228">228</a></p>
<p id="n229" class="stm run hide_run"><a href="#n229">229</a></p>
<p id="n230" class="pln"><a href="#n230">230</a></p>
<p id="n231" class="pln"><a href="#n231">231</a></p>
<p id="n232" class="pln"><a href="#n232">232</a></p>
<p id="n233" class="pln"><a href="#n233">233</a></p>
<p id="n234" class="pln"><a href="#n234">234</a></p>
<p id="n235" class="pln"><a href="#n235">235</a></p>
<p id="n236" class="pln"><a href="#n236">236</a></p>
<p id="n237" class="stm mis"><a href="#n237">237</a></p>
<p id="n238" class="stm mis"><a href="#n238">238</a></p>
<p id="n239" class="stm mis"><a href="#n239">239</a></p>
<p id="n240" class="pln"><a href="#n240">240</a></p>
<p id="n241" class="stm run hide_run"><a href="#n241">241</a></p>
<p id="n242" class="pln"><a href="#n242">242</a></p>
<p id="n243" class="stm mis"><a href="#n243">243</a></p>
<p id="n244" class="pln"><a href="#n244">244</a></p>
<p id="n245" class="stm run hide_run"><a href="#n245">245</a></p>
<p id="n246" class="pln"><a href="#n246">246</a></p>
<p id="n247" class="stm mis"><a href="#n247">247</a></p>
<p id="n248" class="pln"><a href="#n248">248</a></p>
<p id="n249" class="stm run hide_run"><a href="#n249">249</a></p>
<p id="n250" class="pln"><a href="#n250">250</a></p>
<p id="n251" class="stm mis"><a href="#n251">251</a></p>
<p id="n252" class="pln"><a href="#n252">252</a></p>
<p id="n253" class="stm run hide_run"><a href="#n253">253</a></p>
<p id="n254" class="pln"><a href="#n254">254</a></p>
<p id="n255" class="pln"><a href="#n255">255</a></p>
<p id="n256" class="stm mis"><a href="#n256">256</a></p>
<p id="n257" class="pln"><a href="#n257">257</a></p>
<p id="n258" class="stm run hide_run"><a href="#n258">258</a></p>
<p id="n259" class="pln"><a href="#n259">259</a></p>
<p id="n260" class="pln"><a href="#n260">260</a></p>
<p id="n261" class="pln"><a href="#n261">261</a></p>
<p id="n262" class="pln"><a href="#n262">262</a></p>
<p id="n263" class="pln"><a href="#n263">263</a></p>
<p id="n264" class="pln"><a href="#n264">264</a></p>
<p id="n265" class="pln"><a href="#n265">265</a></p>
<p id="n266" class="pln"><a href="#n266">266</a></p>
<p id="n267" class="pln"><a href="#n267">267</a></p>
<p id="n268" class="pln"><a href="#n268">268</a></p>
<p id="n269" class="pln"><a href="#n269">269</a></p>
<p id="n270" class="stm mis"><a href="#n270">270</a></p>
<p id="n271" class="pln"><a href="#n271">271</a></p>
<p id="n272" class="pln"><a href="#n272">272</a></p>
<p id="n273" class="pln"><a href="#n273">273</a></p>
<p id="n274" class="stm mis"><a href="#n274">274</a></p>
<p id="n275" class="stm mis"><a href="#n275">275</a></p>
<p id="n276" class="pln"><a href="#n276">276</a></p>
<p id="n277" class="stm mis"><a href="#n277">277</a></p>
<p id="n278" class="stm mis"><a href="#n278">278</a></p>
<p id="n279" class="stm mis"><a href="#n279">279</a></p>
<p id="n280" class="pln"><a href="#n280">280</a></p>
<p id="n281" class="stm mis"><a href="#n281">281</a></p>
<p id="n282" class="pln"><a href="#n282">282</a></p>
<p id="n283" class="stm run hide_run"><a href="#n283">283</a></p>
<p id="n284" class="pln"><a href="#n284">284</a></p>
<p id="n285" class="stm run hide_run"><a href="#n285">285</a></p>
<p id="n286" class="pln"><a href="#n286">286</a></p>
<p id="n287" class="stm mis"><a href="#n287">287</a></p>
<p id="n288" class="stm mis"><a href="#n288">288</a></p>
<p id="n289" class="stm mis"><a href="#n289">289</a></p>
<p id="n290" class="pln"><a href="#n290">290</a></p>
<p id="n291" class="stm mis"><a href="#n291">291</a></p>
<p id="n292" class="pln"><a href="#n292">292</a></p>
<p id="n293" class="pln"><a href="#n293">293</a></p>
<p id="n294" class="stm run hide_run"><a href="#n294">294</a></p>
<p id="n295" class="pln"><a href="#n295">295</a></p>
<p id="n296" class="pln"><a href="#n296">296</a></p>
<p id="n297" class="pln"><a href="#n297">297</a></p>
<p id="n298" class="stm run hide_run"><a href="#n298">298</a></p>
<p id="n299" class="pln"><a href="#n299">299</a></p>
<p id="n300" class="pln"><a href="#n300">300</a></p>
<p id="n301" class="pln"><a href="#n301">301</a></p>
<p id="n302" class="pln"><a href="#n302">302</a></p>
<p id="n303" class="pln"><a href="#n303">303</a></p>
<p id="n304" class="pln"><a href="#n304">304</a></p>
<p id="n305" class="stm run hide_run"><a href="#n305">305</a></p>
<p id="n306" class="pln"><a href="#n306">306</a></p>
<p id="n307" class="pln"><a href="#n307">307</a></p>
<p id="n308" class="pln"><a href="#n308">308</a></p>
<p id="n309" class="pln"><a href="#n309">309</a></p>
<p id="n310" class="pln"><a href="#n310">310</a></p>
<p id="n311" class="pln"><a href="#n311">311</a></p>
<p id="n312" class="pln"><a href="#n312">312</a></p>
<p id="n313" class="pln"><a href="#n313">313</a></p>
<p id="n314" class="pln"><a href="#n314">314</a></p>
<p id="n315" class="stm mis"><a href="#n315">315</a></p>
<p id="n316" class="stm mis"><a href="#n316">316</a></p>
<p id="n317" class="stm mis"><a href="#n317">317</a></p>
<p id="n318" class="stm mis"><a href="#n318">318</a></p>
<p id="n319" class="pln"><a href="#n319">319</a></p>
<p id="n320" class="stm run hide_run"><a href="#n320">320</a></p>
<p id="n321" class="stm mis"><a href="#n321">321</a></p>
<p id="n322" class="stm mis"><a href="#n322">322</a></p>
<p id="n323" class="stm mis"><a href="#n323">323</a></p>
<p id="n324" class="stm mis"><a href="#n324">324</a></p>
<p id="n325" class="stm mis"><a href="#n325">325</a></p>
<p id="n326" class="stm mis"><a href="#n326">326</a></p>
<p id="n327" class="stm mis"><a href="#n327">327</a></p>
<p id="n328" class="stm mis"><a href="#n328">328</a></p>
<p id="n329" class="stm mis"><a href="#n329">329</a></p>
<p id="n330" class="stm mis"><a href="#n330">330</a></p>
<p id="n331" class="pln"><a href="#n331">331</a></p>
<p id="n332" class="pln"><a href="#n332">332</a></p>
<p id="n333" class="stm mis"><a href="#n333">333</a></p>
<p id="n334" class="stm mis"><a href="#n334">334</a></p>
<p id="n335" class="pln"><a href="#n335">335</a></p>
<p id="n336" class="stm mis"><a href="#n336">336</a></p>
<p id="n337" class="stm mis"><a href="#n337">337</a></p>
<p id="n338" class="stm mis"><a href="#n338">338</a></p>
<p id="n339" class="pln"><a href="#n339">339</a></p>
<p id="n340" class="stm mis"><a href="#n340">340</a></p>
<p id="n341" class="pln"><a href="#n341">341</a></p>
<p id="n342" class="stm mis"><a href="#n342">342</a></p>
<p id="n343" class="stm mis"><a href="#n343">343</a></p>
<p id="n344" class="stm mis"><a href="#n344">344</a></p>
<p id="n345" class="stm mis"><a href="#n345">345</a></p>
<p id="n346" class="stm mis"><a href="#n346">346</a></p>
<p id="n347" class="stm mis"><a href="#n347">347</a></p>
<p id="n348" class="pln"><a href="#n348">348</a></p>
<p id="n349" class="pln"><a href="#n349">349</a></p>
<p id="n350" class="stm mis"><a href="#n350">350</a></p>
<p id="n351" class="pln"><a href="#n351">351</a></p>
<p id="n352" class="pln"><a href="#n352">352</a></p>
<p id="n353" class="pln"><a href="#n353">353</a></p>
<p id="n354" class="stm mis"><a href="#n354">354</a></p>
<p id="n355" class="pln"><a href="#n355">355</a></p>
<p id="n356" class="stm run hide_run"><a href="#n356">356</a></p>
<p id="n357" class="pln"><a href="#n357">357</a></p>
<p id="n358" class="pln"><a href="#n358">358</a></p>
<p id="n359" class="pln"><a href="#n359">359</a></p>
<p id="n360" class="pln"><a href="#n360">360</a></p>
<p id="n361" class="pln"><a href="#n361">361</a></p>
<p id="n362" class="pln"><a href="#n362">362</a></p>
<p id="n363" class="pln"><a href="#n363">363</a></p>
<p id="n364" class="pln"><a href="#n364">364</a></p>
<p id="n365" class="pln"><a href="#n365">365</a></p>
<p id="n366" class="pln"><a href="#n366">366</a></p>
<p id="n367" class="pln"><a href="#n367">367</a></p>
<p id="n368" class="stm mis"><a href="#n368">368</a></p>
<p id="n369" class="stm mis"><a href="#n369">369</a></p>
<p id="n370" class="stm mis"><a href="#n370">370</a></p>
<p id="n371" class="stm mis"><a href="#n371">371</a></p>
<p id="n372" class="stm mis"><a href="#n372">372</a></p>
<p id="n373" class="stm mis"><a href="#n373">373</a></p>
<p id="n374" class="stm mis"><a href="#n374">374</a></p>
<p id="n375" class="stm mis"><a href="#n375">375</a></p>
<p id="n376" class="pln"><a href="#n376">376</a></p>
<p id="n377" class="stm mis"><a href="#n377">377</a></p>
<p id="n378" class="stm mis"><a href="#n378">378</a></p>
<p id="n379" class="pln"><a href="#n379">379</a></p>
<p id="n380" class="pln"><a href="#n380">380</a></p>
<p id="n381" class="stm run hide_run"><a href="#n381">381</a></p>
<p id="n382" class="pln"><a href="#n382">382</a></p>
<p id="n383" class="pln"><a href="#n383">383</a></p>
<p id="n384" class="pln"><a href="#n384">384</a></p>
<p id="n385" class="pln"><a href="#n385">385</a></p>
<p id="n386" class="pln"><a href="#n386">386</a></p>
<p id="n387" class="pln"><a href="#n387">387</a></p>
<p id="n388" class="pln"><a href="#n388">388</a></p>
<p id="n389" class="pln"><a href="#n389">389</a></p>
<p id="n390" class="pln"><a href="#n390">390</a></p>
<p id="n391" class="pln"><a href="#n391">391</a></p>
<p id="n392" class="pln"><a href="#n392">392</a></p>
<p id="n393" class="pln"><a href="#n393">393</a></p>
<p id="n394" class="pln"><a href="#n394">394</a></p>
<p id="n395" class="pln"><a href="#n395">395</a></p>
<p id="n396" class="pln"><a href="#n396">396</a></p>
<p id="n397" class="stm mis"><a href="#n397">397</a></p>
<p id="n398" class="stm mis"><a href="#n398">398</a></p>
<p id="n399" class="pln"><a href="#n399">399</a></p>
<p id="n400" class="stm mis"><a href="#n400">400</a></p>
<p id="n401" class="stm mis"><a href="#n401">401</a></p>
<p id="n402" class="stm mis"><a href="#n402">402</a></p>
<p id="n403" class="stm mis"><a href="#n403">403</a></p>
<p id="n404" class="stm mis"><a href="#n404">404</a></p>
<p id="n405" class="stm mis"><a href="#n405">405</a></p>
<p id="n406" class="pln"><a href="#n406">406</a></p>
<p id="n407" class="stm mis"><a href="#n407">407</a></p>
<p id="n408" class="stm mis"><a href="#n408">408</a></p>
<p id="n409" class="stm mis"><a href="#n409">409</a></p>
<p id="n410" class="stm mis"><a href="#n410">410</a></p>
<p id="n411" class="pln"><a href="#n411">411</a></p>
<p id="n412" class="stm mis"><a href="#n412">412</a></p>
<p id="n413" class="pln"><a href="#n413">413</a></p>
<p id="n414" class="pln"><a href="#n414">414</a></p>
<p id="n415" class="stm run hide_run"><a href="#n415">415</a></p>
<p id="n416" class="pln"><a href="#n416">416</a></p>
<p id="n417" class="pln"><a href="#n417">417</a></p>
<p id="n418" class="pln"><a href="#n418">418</a></p>
<p id="n419" class="pln"><a href="#n419">419</a></p>
<p id="n420" class="pln"><a href="#n420">420</a></p>
<p id="n421" class="pln"><a href="#n421">421</a></p>
<p id="n422" class="pln"><a href="#n422">422</a></p>
<p id="n423" class="pln"><a href="#n423">423</a></p>
<p id="n424" class="pln"><a href="#n424">424</a></p>
<p id="n425" class="pln"><a href="#n425">425</a></p>
<p id="n426" class="pln"><a href="#n426">426</a></p>
<p id="n427" class="pln"><a href="#n427">427</a></p>
<p id="n428" class="pln"><a href="#n428">428</a></p>
<p id="n429" class="pln"><a href="#n429">429</a></p>
<p id="n430" class="pln"><a href="#n430">430</a></p>
<p id="n431" class="pln"><a href="#n431">431</a></p>
<p id="n432" class="stm run hide_run"><a href="#n432">432</a></p>
<p id="n433" class="stm run hide_run"><a href="#n433">433</a></p>
<p id="n434" class="stm run hide_run"><a href="#n434">434</a></p>
<p id="n435" class="pln"><a href="#n435">435</a></p>
<p id="n436" class="pln"><a href="#n436">436</a></p>
<p id="n437" class="stm run hide_run"><a href="#n437">437</a></p>
<p id="n438" class="pln"><a href="#n438">438</a></p>
<p id="n439" class="stm run hide_run"><a href="#n439">439</a></p>
<p id="n440" class="stm run hide_run"><a href="#n440">440</a></p>
<p id="n441" class="pln"><a href="#n441">441</a></p>
<p id="n442" class="stm run hide_run"><a href="#n442">442</a></p>
<p id="n443" class="stm run hide_run"><a href="#n443">443</a></p>
<p id="n444" class="pln"><a href="#n444">444</a></p>
<p id="n445" class="stm run hide_run"><a href="#n445">445</a></p>
<p id="n446" class="stm run hide_run"><a href="#n446">446</a></p>
<p id="n447" class="pln"><a href="#n447">447</a></p>
<p id="n448" class="stm run hide_run"><a href="#n448">448</a></p>
<p id="n449" class="stm mis"><a href="#n449">449</a></p>
<p id="n450" class="pln"><a href="#n450">450</a></p>
<p id="n451" class="stm run hide_run"><a href="#n451">451</a></p>
<p id="n452" class="pln"><a href="#n452">452</a></p>
<p id="n453" class="pln"><a href="#n453">453</a></p>
<p id="n454" class="stm run hide_run"><a href="#n454">454</a></p>
<p id="n455" class="pln"><a href="#n455">455</a></p>
<p id="n456" class="pln"><a href="#n456">456</a></p>
<p id="n457" class="pln"><a href="#n457">457</a></p>
<p id="n458" class="pln"><a href="#n458">458</a></p>
<p id="n459" class="pln"><a href="#n459">459</a></p>
<p id="n460" class="pln"><a href="#n460">460</a></p>
<p id="n461" class="pln"><a href="#n461">461</a></p>
<p id="n462" class="pln"><a href="#n462">462</a></p>
<p id="n463" class="pln"><a href="#n463">463</a></p>
<p id="n464" class="pln"><a href="#n464">464</a></p>
<p id="n465" class="pln"><a href="#n465">465</a></p>
<p id="n466" class="pln"><a href="#n466">466</a></p>
<p id="n467" class="pln"><a href="#n467">467</a></p>
<p id="n468" class="pln"><a href="#n468">468</a></p>
<p id="n469" class="pln"><a href="#n469">469</a></p>
<p id="n470" class="stm mis"><a href="#n470">470</a></p>
<p id="n471" class="stm mis"><a href="#n471">471</a></p>
<p id="n472" class="pln"><a href="#n472">472</a></p>
<p id="n473" class="stm mis"><a href="#n473">473</a></p>
<p id="n474" class="stm mis"><a href="#n474">474</a></p>
<p id="n475" class="pln"><a href="#n475">475</a></p>
<p id="n476" class="stm mis"><a href="#n476">476</a></p>
<p id="n477" class="stm mis"><a href="#n477">477</a></p>
<p id="n478" class="pln"><a href="#n478">478</a></p>
<p id="n479" class="stm mis"><a href="#n479">479</a></p>
<p id="n480" class="stm mis"><a href="#n480">480</a></p>
<p id="n481" class="pln"><a href="#n481">481</a></p>
<p id="n482" class="stm mis"><a href="#n482">482</a></p>
<p id="n483" class="pln"><a href="#n483">483</a></p>
<p id="n484" class="pln"><a href="#n484">484</a></p>
<p id="n485" class="stm run hide_run"><a href="#n485">485</a></p>
<p id="n486" class="pln"><a href="#n486">486</a></p>
<p id="n487" class="pln"><a href="#n487">487</a></p>
<p id="n488" class="pln"><a href="#n488">488</a></p>
<p id="n489" class="pln"><a href="#n489">489</a></p>
<p id="n490" class="pln"><a href="#n490">490</a></p>
<p id="n491" class="pln"><a href="#n491">491</a></p>
<p id="n492" class="pln"><a href="#n492">492</a></p>
<p id="n493" class="pln"><a href="#n493">493</a></p>
<p id="n494" class="pln"><a href="#n494">494</a></p>
<p id="n495" class="pln"><a href="#n495">495</a></p>
<p id="n496" class="pln"><a href="#n496">496</a></p>
<p id="n497" class="pln"><a href="#n497">497</a></p>
<p id="n498" class="pln"><a href="#n498">498</a></p>
<p id="n499" class="pln"><a href="#n499">499</a></p>
<p id="n500" class="pln"><a href="#n500">500</a></p>
<p id="n501" class="pln"><a href="#n501">501</a></p>
<p id="n502" class="pln"><a href="#n502">502</a></p>
<p id="n503" class="pln"><a href="#n503">503</a></p>
<p id="n504" class="stm run hide_run"><a href="#n504">504</a></p>
<p id="n505" class="stm run hide_run"><a href="#n505">505</a></p>
<p id="n506" class="pln"><a href="#n506">506</a></p>
<p id="n507" class="stm run hide_run"><a href="#n507">507</a></p>
<p id="n508" class="stm run hide_run"><a href="#n508">508</a></p>
<p id="n509" class="pln"><a href="#n509">509</a></p>
<p id="n510" class="stm run hide_run"><a href="#n510">510</a></p>
<p id="n511" class="stm run hide_run"><a href="#n511">511</a></p>
<p id="n512" class="stm mis"><a href="#n512">512</a></p>
<p id="n513" class="stm mis"><a href="#n513">513</a></p>
<p id="n514" class="pln"><a href="#n514">514</a></p>
<p id="n515" class="stm run hide_run"><a href="#n515">515</a></p>

            </td>
            <td class="text">
<p id="t1" class="pln"><span class="com"># Copyright 2017 The TensorFlow Authors. All Rights Reserved.</span><span class="strut">&nbsp;</span></p>
<p id="t2" class="pln"><span class="com">#</span><span class="strut">&nbsp;</span></p>
<p id="t3" class="pln"><span class="com"># Licensed under the Apache License, Version 2.0 (the "License");</span><span class="strut">&nbsp;</span></p>
<p id="t4" class="pln"><span class="com"># you may not use this file except in compliance with the License.</span><span class="strut">&nbsp;</span></p>
<p id="t5" class="pln"><span class="com"># You may obtain a copy of the License at</span><span class="strut">&nbsp;</span></p>
<p id="t6" class="pln"><span class="com">#</span><span class="strut">&nbsp;</span></p>
<p id="t7" class="pln"><span class="com">#     http://www.apache.org/licenses/LICENSE-2.0</span><span class="strut">&nbsp;</span></p>
<p id="t8" class="pln"><span class="com">#</span><span class="strut">&nbsp;</span></p>
<p id="t9" class="pln"><span class="com"># Unless required by applicable law or agreed to in writing, software</span><span class="strut">&nbsp;</span></p>
<p id="t10" class="pln"><span class="com"># distributed under the License is distributed on an "AS IS" BASIS,</span><span class="strut">&nbsp;</span></p>
<p id="t11" class="pln"><span class="com"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><span class="strut">&nbsp;</span></p>
<p id="t12" class="pln"><span class="com"># See the License for the specific language governing permissions and</span><span class="strut">&nbsp;</span></p>
<p id="t13" class="pln"><span class="com"># limitations under the License.</span><span class="strut">&nbsp;</span></p>
<p id="t14" class="pln"><span class="com"># ==============================================================================</span><span class="strut">&nbsp;</span></p>
<p id="t15" class="stm run hide_run"><span class="str">"""Utilities for VariableMgr."""</span><span class="strut">&nbsp;</span></p>
<p id="t16" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t17" class="stm run hide_run"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">print_function</span><span class="strut">&nbsp;</span></p>
<p id="t18" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t19" class="stm run hide_run"><span class="key">import</span> <span class="nam">collections</span> <span class="key">as</span> <span class="nam">pycoll</span><span class="strut">&nbsp;</span></p>
<p id="t20" class="stm run hide_run"><span class="key">import</span> <span class="nam">operator</span><span class="strut">&nbsp;</span></p>
<p id="t21" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t22" class="stm run hide_run"><span class="key">import</span> <span class="nam">tensorflow</span> <span class="key">as</span> <span class="nam">tf</span><span class="strut">&nbsp;</span></p>
<p id="t23" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t24" class="stm run hide_run"><span class="key">from</span> <span class="nam">tensorflow</span><span class="op">.</span><span class="nam">python</span><span class="op">.</span><span class="nam">framework</span> <span class="key">import</span> <span class="nam">ops</span><span class="strut">&nbsp;</span></p>
<p id="t25" class="stm run hide_run"><span class="key">from</span> <span class="nam">tensorflow</span><span class="op">.</span><span class="nam">python</span><span class="op">.</span><span class="nam">ops</span> <span class="key">import</span> <span class="nam">data_flow_ops</span><span class="strut">&nbsp;</span></p>
<p id="t26" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t27" class="stm run hide_run"><span class="nam">PS_SHADOW_VAR_PREFIX</span> <span class="op">=</span> <span class="str">'ps_var'</span><span class="strut">&nbsp;</span></p>
<p id="t28" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t29" class="stm run hide_run"><span class="nam">AutoLossScaleParams</span> <span class="op">=</span> <span class="nam">pycoll</span><span class="op">.</span><span class="nam">namedtuple</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t30" class="pln">    <span class="str">'AutoLossScaleParams'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t31" class="pln">    <span class="op">[</span><span class="strut">&nbsp;</span></p>
<p id="t32" class="pln">        <span class="com"># If true, enable automatic loss scaling.</span><span class="strut">&nbsp;</span></p>
<p id="t33" class="pln">        <span class="str">'enable_auto_loss_scale'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t34" class="pln">        <span class="com"># The value to scale the loss before computing gradients.</span><span class="strut">&nbsp;</span></p>
<p id="t35" class="pln">        <span class="str">'loss_scale'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t36" class="pln">        <span class="com"># Number of normal steps with the current `loss_scale`.</span><span class="strut">&nbsp;</span></p>
<p id="t37" class="pln">        <span class="str">'loss_scale_normal_steps'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t38" class="pln">        <span class="com"># Increase loss scale every n steps.</span><span class="strut">&nbsp;</span></p>
<p id="t39" class="pln">        <span class="str">'inc_loss_scale_every_n'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t40" class="pln">        <span class="com"># If true, the current worker is chief. The current implementation</span><span class="strut">&nbsp;</span></p>
<p id="t41" class="pln">        <span class="com"># relies on the chief to update loss_scale value, but in future, we</span><span class="strut">&nbsp;</span></p>
<p id="t42" class="pln">        <span class="com"># might change this to ask the parameter server to update loss_scales</span><span class="strut">&nbsp;</span></p>
<p id="t43" class="pln">        <span class="com"># for better performance.</span><span class="strut">&nbsp;</span></p>
<p id="t44" class="pln">        <span class="com"># TODO(tanmingxing): remove this if loss_scale is updated in ps.</span><span class="strut">&nbsp;</span></p>
<p id="t45" class="pln">        <span class="str">'is_chief'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t46" class="pln">    <span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t47" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t48" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t49" class="stm run hide_run"><span class="key">def</span> <span class="nam">get_loss_scale_update_op</span><span class="op">(</span><span class="nam">loss_scale</span><span class="op">,</span> <span class="nam">loss_scale_normal_steps</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t50" class="pln">                             <span class="nam">inc_loss_scale_every_n</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t51" class="pln">  <span class="str">"""Returns the update op for loss scaling variables.</span><span class="strut">&nbsp;</span></p>
<p id="t52" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t53" class="pln"><span class="str">  We maintain the counter `loss_scale_normal_steps` to count the number of steps</span><span class="strut">&nbsp;</span></p>
<p id="t54" class="pln"><span class="str">  we have been using the current `loss_scale`. In most cases, this function</span><span class="strut">&nbsp;</span></p>
<p id="t55" class="pln"><span class="str">  increments `loss_scale_normal_steps`. However, if `loss_scale_normal_steps` is</span><span class="strut">&nbsp;</span></p>
<p id="t56" class="pln"><span class="str">  greater than the threshold `inc_loss_scale_every_n`, we double `loss_scale`</span><span class="strut">&nbsp;</span></p>
<p id="t57" class="pln"><span class="str">  and reset `loss_scale_normal_steps` to zero.</span><span class="strut">&nbsp;</span></p>
<p id="t58" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t59" class="pln"><span class="str">  This op is only called if the gradients don't have any infs or nans. Instead,</span><span class="strut">&nbsp;</span></p>
<p id="t60" class="pln"><span class="str">  if infs or nans occur in the gradients, we immeditately halve `loss_scale` and</span><span class="strut">&nbsp;</span></p>
<p id="t61" class="pln"><span class="str">  reset `loss_scale_normal_steps` to zero.</span><span class="strut">&nbsp;</span></p>
<p id="t62" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t63" class="pln"><span class="str">  Args:</span><span class="strut">&nbsp;</span></p>
<p id="t64" class="pln"><span class="str">    loss_scale: a tf.Variable represneting the loss_scale value.</span><span class="strut">&nbsp;</span></p>
<p id="t65" class="pln"><span class="str">    loss_scale_normal_steps: a tf.Variable representing the number of training</span><span class="strut">&nbsp;</span></p>
<p id="t66" class="pln"><span class="str">      steps that have run since the loss_scale last changed.</span><span class="strut">&nbsp;</span></p>
<p id="t67" class="pln"><span class="str">    inc_loss_scale_every_n: a Python integer threshold. `loss_scale` is</span><span class="strut">&nbsp;</span></p>
<p id="t68" class="pln"><span class="str">      increased every `inc_loss_scale_every_n` steps, unless the gradients have</span><span class="strut">&nbsp;</span></p>
<p id="t69" class="pln"><span class="str">      infs or nans.</span><span class="strut">&nbsp;</span></p>
<p id="t70" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t71" class="pln"><span class="str">  Returns:</span><span class="strut">&nbsp;</span></p>
<p id="t72" class="pln"><span class="str">    An op for updating `loss_scale` and `loss_scale_normal_steps`.</span><span class="strut">&nbsp;</span></p>
<p id="t73" class="pln"><span class="str">  """</span><span class="strut">&nbsp;</span></p>
<p id="t74" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t75" class="stm mis">  <span class="key">def</span> <span class="nam">increment_loss_scale_normal_steps_func</span><span class="op">(</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t76" class="stm mis">    <span class="key">return</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">group</span><span class="op">(</span><span class="nam">loss_scale_normal_steps</span><span class="op">.</span><span class="nam">assign_add</span><span class="op">(</span><span class="num">1</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t77" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t78" class="stm mis">  <span class="key">def</span> <span class="nam">increase_loss_scale_func</span><span class="op">(</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t79" class="stm mis">    <span class="key">return</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">group</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t80" class="pln">        <span class="nam">tf</span><span class="op">.</span><span class="nam">assign</span><span class="op">(</span><span class="nam">loss_scale_normal_steps</span><span class="op">,</span> <span class="num">0</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t81" class="pln">        <span class="nam">tf</span><span class="op">.</span><span class="nam">assign</span><span class="op">(</span><span class="nam">loss_scale</span><span class="op">,</span> <span class="nam">loss_scale</span> <span class="op">*</span> <span class="num">2</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t82" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t83" class="pln">  <span class="com"># true_fn and false_fn must have the same type.</span><span class="strut">&nbsp;</span></p>
<p id="t84" class="stm mis">  <span class="key">return</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">cond</span><span class="op">(</span><span class="nam">loss_scale_normal_steps</span> <span class="op">&lt;</span> <span class="nam">inc_loss_scale_every_n</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t85" class="pln">                 <span class="nam">increment_loss_scale_normal_steps_func</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t86" class="pln">                 <span class="nam">increase_loss_scale_func</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t87" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t88" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t89" class="stm run hide_run"><span class="key">def</span> <span class="nam">append_gradients_with_loss_scale</span><span class="op">(</span><span class="nam">training_ops</span><span class="op">,</span> <span class="nam">get_apply_gradients_ops_func</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t90" class="pln">                                     <span class="nam">loss_scale_params</span><span class="op">,</span> <span class="nam">grad_has_inf_nan</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t91" class="pln">  <span class="str">"""Selectively appends gradients update ops with loss scaling.</span><span class="strut">&nbsp;</span></p>
<p id="t92" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t93" class="pln"><span class="str">  Args:</span><span class="strut">&nbsp;</span></p>
<p id="t94" class="pln"><span class="str">    training_ops: a list of training ops to be executed.</span><span class="strut">&nbsp;</span></p>
<p id="t95" class="pln"><span class="str">    get_apply_gradients_ops_func: a function that returns a list of ops for</span><span class="strut">&nbsp;</span></p>
<p id="t96" class="pln"><span class="str">      applying gradients. Here, we must pass a function instead of the actual</span><span class="strut">&nbsp;</span></p>
<p id="t97" class="pln"><span class="str">      list of ops; otherwise, those ops would be executed unconditionally due to</span><span class="strut">&nbsp;</span></p>
<p id="t98" class="pln"><span class="str">      the sementics of tf.cond.</span><span class="strut">&nbsp;</span></p>
<p id="t99" class="pln"><span class="str">    loss_scale_params: An AutoLossScaleParams tuple.</span><span class="strut">&nbsp;</span></p>
<p id="t100" class="pln"><span class="str">    grad_has_inf_nan: Boolean tensor indicating whether the gradients have infs</span><span class="strut">&nbsp;</span></p>
<p id="t101" class="pln"><span class="str">      or nans.</span><span class="strut">&nbsp;</span></p>
<p id="t102" class="pln"><span class="str">  """</span><span class="strut">&nbsp;</span></p>
<p id="t103" class="stm run hide_run">  <span class="nam">is_chief</span> <span class="op">=</span> <span class="nam">loss_scale_params</span><span class="op">.</span><span class="nam">is_chief</span><span class="strut">&nbsp;</span></p>
<p id="t104" class="stm run hide_run">  <span class="nam">loss_scale</span> <span class="op">=</span> <span class="nam">loss_scale_params</span><span class="op">.</span><span class="nam">loss_scale</span><span class="strut">&nbsp;</span></p>
<p id="t105" class="stm run hide_run">  <span class="nam">loss_scale_normal_steps</span> <span class="op">=</span> <span class="nam">loss_scale_params</span><span class="op">.</span><span class="nam">loss_scale_normal_steps</span><span class="strut">&nbsp;</span></p>
<p id="t106" class="stm run hide_run">  <span class="nam">inc_loss_scale_every_n</span> <span class="op">=</span> <span class="nam">loss_scale_params</span><span class="op">.</span><span class="nam">inc_loss_scale_every_n</span><span class="strut">&nbsp;</span></p>
<p id="t107" class="stm run hide_run">  <span class="nam">enable_auto_loss_scale</span> <span class="op">=</span> <span class="nam">loss_scale_params</span><span class="op">.</span><span class="nam">enable_auto_loss_scale</span><span class="strut">&nbsp;</span></p>
<p id="t108" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t109" class="stm run hide_run">  <span class="key">if</span> <span class="nam">loss_scale</span> <span class="key">is</span> <span class="key">None</span> <span class="key">or</span> <span class="key">not</span> <span class="nam">enable_auto_loss_scale</span> <span class="key">or</span> <span class="key">not</span> <span class="nam">is_chief</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t110" class="stm run hide_run">    <span class="nam">training_ops</span><span class="op">.</span><span class="nam">extend</span><span class="op">(</span><span class="nam">get_apply_gradients_ops_func</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t111" class="pln">  <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t112" class="pln">    <span class="com"># If nans/infs occurred, skip applying gradients and instead update</span><span class="strut">&nbsp;</span></p>
<p id="t113" class="pln">    <span class="com"># loss_scale (halve loss_scale and reset loss_scale_normal_steps to zero).</span><span class="strut">&nbsp;</span></p>
<p id="t114" class="stm mis">    <span class="key">def</span> <span class="nam">update_op_if_nan_or_inf</span><span class="op">(</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t115" class="pln">      <span class="str">"""Update loss_scale and discard gradients if nans/infs occurred."""</span><span class="strut">&nbsp;</span></p>
<p id="t116" class="stm mis">      <span class="key">return</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">group</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t117" class="pln">          <span class="nam">tf</span><span class="op">.</span><span class="nam">assign</span><span class="op">(</span><span class="nam">loss_scale</span><span class="op">,</span> <span class="nam">loss_scale</span> <span class="op">/</span> <span class="num">2.</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t118" class="pln">          <span class="nam">tf</span><span class="op">.</span><span class="nam">assign</span><span class="op">(</span><span class="nam">loss_scale_normal_steps</span><span class="op">,</span> <span class="num">0</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t119" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t120" class="pln">    <span class="com"># Otherwise, apply gradients, and update loss_scale and</span><span class="strut">&nbsp;</span></p>
<p id="t121" class="pln">    <span class="com"># loss_scale_normal_steps.</span><span class="strut">&nbsp;</span></p>
<p id="t122" class="stm mis">    <span class="key">def</span> <span class="nam">update_op_if_no_nan_or_inf</span><span class="op">(</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t123" class="pln">      <span class="str">"""Apply gradients, and update loss scaling."""</span><span class="strut">&nbsp;</span></p>
<p id="t124" class="stm mis">      <span class="key">return</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">group</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t125" class="pln">          <span class="nam">get_loss_scale_update_op</span><span class="op">(</span><span class="nam">loss_scale</span><span class="op">,</span> <span class="nam">loss_scale_normal_steps</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t126" class="pln">                                   <span class="nam">inc_loss_scale_every_n</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t127" class="pln">          <span class="op">*</span><span class="nam">get_apply_gradients_ops_func</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t128" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t129" class="pln">    <span class="com"># TODO(tanmingxing): Add support for independent and distributed all_reduce.</span><span class="strut">&nbsp;</span></p>
<p id="t130" class="stm mis">    <span class="key">assert</span> <span class="nam">grad_has_inf_nan</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t131" class="stm mis">    <span class="nam">update_op</span> <span class="op">=</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">cond</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t132" class="pln">        <span class="nam">grad_has_inf_nan</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t133" class="pln">        <span class="nam">update_op_if_nan_or_inf</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t134" class="pln">        <span class="nam">update_op_if_no_nan_or_inf</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t135" class="pln">    <span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t136" class="stm mis">    <span class="nam">training_ops</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">update_op</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t137" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t138" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t139" class="pln"><span class="com"># To be used with custom_getter on tf.get_variable.</span><span class="strut">&nbsp;</span></p>
<p id="t140" class="stm run hide_run"><span class="key">class</span> <span class="nam">OverrideCachingDevice</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t141" class="pln">  <span class="str">"""Variable getter which caches variables on the least loaded device.</span><span class="strut">&nbsp;</span></p>
<p id="t142" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t143" class="pln"><span class="str">  Variables smaller than a certain threshold are cached on a single specific</span><span class="strut">&nbsp;</span></p>
<p id="t144" class="pln"><span class="str">  device, as specified in the constructor. All other variables are load balanced</span><span class="strut">&nbsp;</span></p>
<p id="t145" class="pln"><span class="str">  across a pool of devices, by caching each variable on the least loaded device.</span><span class="strut">&nbsp;</span></p>
<p id="t146" class="pln"><span class="str">  """</span><span class="strut">&nbsp;</span></p>
<p id="t147" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t148" class="stm run hide_run">  <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">devices</span><span class="op">,</span> <span class="nam">device_for_small_variables</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t149" class="pln">               <span class="nam">small_variable_size_threshold</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t150" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">devices</span> <span class="op">=</span> <span class="nam">devices</span><span class="strut">&nbsp;</span></p>
<p id="t151" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">sizes</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">*</span> <span class="nam">len</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">devices</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t152" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">device_for_small_variables</span> <span class="op">=</span> <span class="nam">device_for_small_variables</span><span class="strut">&nbsp;</span></p>
<p id="t153" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">small_variable_size_threshold</span> <span class="op">=</span> <span class="nam">small_variable_size_threshold</span><span class="strut">&nbsp;</span></p>
<p id="t154" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t155" class="stm run hide_run">  <span class="key">def</span> <span class="nam">__call__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">getter</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t156" class="stm mis">    <span class="nam">size</span> <span class="op">=</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">TensorShape</span><span class="op">(</span><span class="nam">kwargs</span><span class="op">[</span><span class="str">'shape'</span><span class="op">]</span><span class="op">)</span><span class="op">.</span><span class="nam">num_elements</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t157" class="stm mis">    <span class="key">if</span> <span class="nam">size</span> <span class="op">&lt;</span> <span class="nam">self</span><span class="op">.</span><span class="nam">small_variable_size_threshold</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t158" class="stm mis">      <span class="nam">device_name</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">device_for_small_variables</span><span class="strut">&nbsp;</span></p>
<p id="t159" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t160" class="stm mis">      <span class="nam">device_index</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">min</span><span class="op">(</span><span class="nam">enumerate</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">sizes</span><span class="op">)</span><span class="op">,</span> <span class="nam">key</span><span class="op">=</span><span class="nam">operator</span><span class="op">.</span><span class="nam">itemgetter</span><span class="op">(</span><span class="num">1</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t161" class="stm mis">      <span class="nam">device_name</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">devices</span><span class="op">[</span><span class="nam">device_index</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t162" class="stm mis">      <span class="nam">self</span><span class="op">.</span><span class="nam">sizes</span><span class="op">[</span><span class="nam">device_index</span><span class="op">]</span> <span class="op">+=</span> <span class="nam">size</span><span class="strut">&nbsp;</span></p>
<p id="t163" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t164" class="stm mis">    <span class="nam">kwargs</span><span class="op">[</span><span class="str">'caching_device'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">device_name</span><span class="strut">&nbsp;</span></p>
<p id="t165" class="stm mis">    <span class="nam">var</span> <span class="op">=</span> <span class="nam">getter</span><span class="op">(</span><span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t166" class="stm mis">    <span class="key">return</span> <span class="nam">var</span><span class="strut">&nbsp;</span></p>
<p id="t167" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t168" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t169" class="pln"><span class="com"># To be used with custom_getter on tf.get_variable. Ensures the created variable</span><span class="strut">&nbsp;</span></p>
<p id="t170" class="pln"><span class="com"># is in LOCAL_VARIABLES and not GLOBAL_VARIBLES collection.</span><span class="strut">&nbsp;</span></p>
<p id="t171" class="stm run hide_run"><span class="key">class</span> <span class="nam">OverrideToLocalVariableIfNotPsVar</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t172" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t173" class="pln">  <span class="com"># args and kwargs come from the custom_getter interface for Tensorflow</span><span class="strut">&nbsp;</span></p>
<p id="t174" class="pln">  <span class="com"># variables, and matches tf.get_variable's signature, with the addition of</span><span class="strut">&nbsp;</span></p>
<p id="t175" class="pln">  <span class="com"># 'getter' at the beginning.</span><span class="strut">&nbsp;</span></p>
<p id="t176" class="stm run hide_run">  <span class="key">def</span> <span class="nam">__call__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">getter</span><span class="op">,</span> <span class="nam">name</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t177" class="stm mis">    <span class="key">if</span> <span class="nam">name</span><span class="op">.</span><span class="nam">startswith</span><span class="op">(</span><span class="nam">PS_SHADOW_VAR_PREFIX</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t178" class="stm mis">      <span class="key">return</span> <span class="nam">getter</span><span class="op">(</span><span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t179" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t180" class="stm mis">    <span class="key">if</span> <span class="str">'collections'</span> <span class="key">in</span> <span class="nam">kwargs</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t181" class="stm mis">      <span class="nam">collections</span> <span class="op">=</span> <span class="nam">kwargs</span><span class="op">[</span><span class="str">'collections'</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t182" class="stm mis">    <span class="key">if</span> <span class="key">not</span> <span class="nam">collections</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t183" class="stm mis">      <span class="nam">collections</span> <span class="op">=</span> <span class="op">[</span><span class="nam">tf</span><span class="op">.</span><span class="nam">GraphKeys</span><span class="op">.</span><span class="nam">GLOBAL_VARIABLES</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t184" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t185" class="stm mis">      <span class="nam">collections</span> <span class="op">=</span> <span class="nam">collections</span><span class="op">[</span><span class="op">:</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t186" class="stm mis">    <span class="nam">collections</span><span class="op">.</span><span class="nam">remove</span><span class="op">(</span><span class="nam">tf</span><span class="op">.</span><span class="nam">GraphKeys</span><span class="op">.</span><span class="nam">GLOBAL_VARIABLES</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t187" class="stm mis">    <span class="nam">collections</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">tf</span><span class="op">.</span><span class="nam">GraphKeys</span><span class="op">.</span><span class="nam">LOCAL_VARIABLES</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t188" class="stm mis">    <span class="nam">kwargs</span><span class="op">[</span><span class="str">'collections'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">collections</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t189" class="stm mis">    <span class="key">return</span> <span class="nam">getter</span><span class="op">(</span><span class="nam">name</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t190" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t191" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t192" class="stm run hide_run"><span class="key">class</span> <span class="nam">ParamServerDeviceSetter</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t193" class="pln">  <span class="str">"""Helper class to assign variables on the least loaded ps-device."""</span><span class="strut">&nbsp;</span></p>
<p id="t194" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t195" class="stm run hide_run">  <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">worker_device</span><span class="op">,</span> <span class="nam">ps_devices</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t196" class="pln">    <span class="str">"""Initializer for ParamServerDevicSetter.</span><span class="strut">&nbsp;</span></p>
<p id="t197" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t198" class="pln"><span class="str">    Args:</span><span class="strut">&nbsp;</span></p>
<p id="t199" class="pln"><span class="str">      worker_device: the device to use for computer ops.</span><span class="strut">&nbsp;</span></p>
<p id="t200" class="pln"><span class="str">      ps_devices: a list of device to use for Variable ops. Each variable is</span><span class="strut">&nbsp;</span></p>
<p id="t201" class="pln"><span class="str">      assigned to the least loaded device.</span><span class="strut">&nbsp;</span></p>
<p id="t202" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t203" class="stm run hide_run">    <span class="nam">self</span><span class="op">.</span><span class="nam">ps_devices</span> <span class="op">=</span> <span class="nam">ps_devices</span><span class="strut">&nbsp;</span></p>
<p id="t204" class="stm run hide_run">    <span class="nam">self</span><span class="op">.</span><span class="nam">worker_device</span> <span class="op">=</span> <span class="nam">worker_device</span><span class="strut">&nbsp;</span></p>
<p id="t205" class="stm run hide_run">    <span class="nam">self</span><span class="op">.</span><span class="nam">ps_sizes</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="op">*</span> <span class="nam">len</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">ps_devices</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t206" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t207" class="stm run hide_run">  <span class="key">def</span> <span class="nam">__call__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">op</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t208" class="stm run hide_run">    <span class="key">if</span> <span class="nam">op</span><span class="op">.</span><span class="nam">device</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t209" class="stm mis">      <span class="key">return</span> <span class="nam">op</span><span class="op">.</span><span class="nam">device</span><span class="strut">&nbsp;</span></p>
<p id="t210" class="stm run hide_run">    <span class="key">if</span> <span class="nam">op</span><span class="op">.</span><span class="nam">type</span> <span class="key">not</span> <span class="key">in</span> <span class="op">[</span><span class="str">'Variable'</span><span class="op">,</span> <span class="str">'VariableV2'</span><span class="op">]</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t211" class="stm run hide_run">      <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">worker_device</span><span class="strut">&nbsp;</span></p>
<p id="t212" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t213" class="stm run hide_run">    <span class="nam">device_index</span><span class="op">,</span> <span class="nam">_</span> <span class="op">=</span> <span class="nam">min</span><span class="op">(</span><span class="nam">enumerate</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">ps_sizes</span><span class="op">)</span><span class="op">,</span> <span class="nam">key</span><span class="op">=</span><span class="nam">operator</span><span class="op">.</span><span class="nam">itemgetter</span><span class="op">(</span><span class="num">1</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t214" class="stm run hide_run">    <span class="nam">device_name</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">ps_devices</span><span class="op">[</span><span class="nam">device_index</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t215" class="stm run hide_run">    <span class="nam">var_size</span> <span class="op">=</span> <span class="nam">op</span><span class="op">.</span><span class="nam">outputs</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">.</span><span class="nam">get_shape</span><span class="op">(</span><span class="op">)</span><span class="op">.</span><span class="nam">num_elements</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t216" class="stm run hide_run">    <span class="nam">self</span><span class="op">.</span><span class="nam">ps_sizes</span><span class="op">[</span><span class="nam">device_index</span><span class="op">]</span> <span class="op">+=</span> <span class="nam">var_size</span><span class="strut">&nbsp;</span></p>
<p id="t217" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t218" class="stm run hide_run">    <span class="key">return</span> <span class="nam">device_name</span><span class="strut">&nbsp;</span></p>
<p id="t219" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t220" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t221" class="stm run hide_run"><span class="key">class</span> <span class="nam">StagedModelVariable</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t222" class="pln">  <span class="str">"""Staging variable wrapper that decouples reads and updates.</span><span class="strut">&nbsp;</span></p>
<p id="t223" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t224" class="pln"><span class="str">  This class represents a variable through a staging buffer. Reads from this</span><span class="strut">&nbsp;</span></p>
<p id="t225" class="pln"><span class="str">  variable directly gets from the staging buffer. Updates are stacked into</span><span class="strut">&nbsp;</span></p>
<p id="t226" class="pln"><span class="str">  another staging buffer, and will be processed later.</span><span class="strut">&nbsp;</span></p>
<p id="t227" class="pln"><span class="str">  """</span><span class="strut">&nbsp;</span></p>
<p id="t228" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t229" class="stm run hide_run">  <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">real_var</span><span class="op">,</span> <span class="nam">var_stage_get</span><span class="op">,</span> <span class="nam">variable_mgr</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t230" class="pln">    <span class="str">"""Initializer for the model variables through a staging buffer.</span><span class="strut">&nbsp;</span></p>
<p id="t231" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t232" class="pln"><span class="str">    Args:</span><span class="strut">&nbsp;</span></p>
<p id="t233" class="pln"><span class="str">      real_var: the underlying real variable.</span><span class="strut">&nbsp;</span></p>
<p id="t234" class="pln"><span class="str">      var_stage_get: the read op from the staging buffer.</span><span class="strut">&nbsp;</span></p>
<p id="t235" class="pln"><span class="str">      variable_mgr: the parent variable-manager.</span><span class="strut">&nbsp;</span></p>
<p id="t236" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t237" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">real_var</span> <span class="op">=</span> <span class="nam">real_var</span><span class="strut">&nbsp;</span></p>
<p id="t238" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">var_stage_get</span> <span class="op">=</span> <span class="nam">var_stage_get</span><span class="strut">&nbsp;</span></p>
<p id="t239" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">variable_mgr</span> <span class="op">=</span> <span class="nam">variable_mgr</span><span class="strut">&nbsp;</span></p>
<p id="t240" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t241" class="stm run hide_run">  <span class="key">def</span> <span class="nam">_value</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t242" class="pln">    <span class="str">"""The read access of this variable. The content from the staging buffer."""</span><span class="strut">&nbsp;</span></p>
<p id="t243" class="stm mis">    <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">var_stage_get</span><span class="strut">&nbsp;</span></p>
<p id="t244" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t245" class="stm run hide_run">  <span class="key">def</span> <span class="nam">_ref</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t246" class="pln">    <span class="str">"""Return the underlying variable ref, required by tf.colocate_with."""</span><span class="strut">&nbsp;</span></p>
<p id="t247" class="stm mis">    <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">real_var</span><span class="op">.</span><span class="nam">_ref</span><span class="op">(</span><span class="op">)</span>  <span class="com"># pylint: disable=protected-access</span><span class="strut">&nbsp;</span></p>
<p id="t248" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t249" class="stm run hide_run">  <span class="key">def</span> <span class="nam">read_value</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t250" class="pln">    <span class="str">"""Mimics tf.Variable.read_value()."""</span><span class="strut">&nbsp;</span></p>
<p id="t251" class="stm mis">    <span class="key">return</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">identity</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">var_stage_get</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="str">'read'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t252" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t253" class="stm run hide_run">  <span class="op">@</span><span class="nam">property</span><span class="strut">&nbsp;</span></p>
<p id="t254" class="pln">  <span class="key">def</span> <span class="nam">dtype</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t255" class="pln">    <span class="str">"""Return the non-reference dtype."""</span><span class="strut">&nbsp;</span></p>
<p id="t256" class="stm mis">    <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">var_stage_get</span><span class="op">.</span><span class="nam">dtype</span><span class="strut">&nbsp;</span></p>
<p id="t257" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t258" class="stm run hide_run">  <span class="key">def</span> <span class="nam">assign_sub</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">delta</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t259" class="pln">    <span class="str">"""Mimic the updates to the variable.</span><span class="strut">&nbsp;</span></p>
<p id="t260" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t261" class="pln"><span class="str">    Args:</span><span class="strut">&nbsp;</span></p>
<p id="t262" class="pln"><span class="str">      delta: is pushed into a staging buffer and will be pumped later.</span><span class="strut">&nbsp;</span></p>
<p id="t263" class="pln"><span class="str">      name: currently ignored; names of ops and the StagingArea are</span><span class="strut">&nbsp;</span></p>
<p id="t264" class="pln"><span class="str">            computed without using this pass name.</span><span class="strut">&nbsp;</span></p>
<p id="t265" class="pln"><span class="str">    Returns:</span><span class="strut">&nbsp;</span></p>
<p id="t266" class="pln"><span class="str">      The actual updates. The colocation constraint will be reapplied.</span><span class="strut">&nbsp;</span></p>
<p id="t267" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t268" class="pln">    <span class="com"># This parameter is ignored: the StagingArea only supports setting</span><span class="strut">&nbsp;</span></p>
<p id="t269" class="pln">    <span class="com"># the shared name, not the names of individual ops it uses.</span><span class="strut">&nbsp;</span></p>
<p id="t270" class="stm mis">    <span class="key">del</span> <span class="nam">name</span><span class="strut">&nbsp;</span></p>
<p id="t271" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t272" class="pln">    <span class="com"># colocate_with(None, True) clears the colocation constraints.</span><span class="strut">&nbsp;</span></p>
<p id="t273" class="pln">    <span class="com"># Push the delta into a staging buffer.</span><span class="strut">&nbsp;</span></p>
<p id="t274" class="stm mis">    <span class="key">with</span> <span class="nam">ops</span><span class="op">.</span><span class="nam">colocate_with</span><span class="op">(</span><span class="key">None</span><span class="op">,</span> <span class="key">True</span><span class="op">)</span><span class="op">,</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">device</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">var_stage_get</span><span class="op">.</span><span class="nam">device</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t275" class="stm mis">      <span class="nam">delta_staging_area</span> <span class="op">=</span> <span class="nam">data_flow_ops</span><span class="op">.</span><span class="nam">StagingArea</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t276" class="pln">          <span class="op">[</span><span class="nam">self</span><span class="op">.</span><span class="nam">var_stage_get</span><span class="op">.</span><span class="nam">dtype</span><span class="op">]</span><span class="op">,</span> <span class="nam">shapes</span><span class="op">=</span><span class="op">[</span><span class="nam">self</span><span class="op">.</span><span class="nam">var_stage_get</span><span class="op">.</span><span class="nam">shape</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t277" class="stm mis">      <span class="nam">delta_put_op</span> <span class="op">=</span> <span class="nam">delta_staging_area</span><span class="op">.</span><span class="nam">put</span><span class="op">(</span><span class="op">[</span><span class="nam">delta</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t278" class="stm mis">      <span class="nam">self</span><span class="op">.</span><span class="nam">variable_mgr</span><span class="op">.</span><span class="nam">staging_delta_ops</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">delta_put_op</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t279" class="stm mis">      <span class="nam">delta_get_op</span> <span class="op">=</span> <span class="nam">delta_staging_area</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t280" class="pln">    <span class="com"># Return the actual updates. The colocation constraint will be reapplied.</span><span class="strut">&nbsp;</span></p>
<p id="t281" class="stm mis">    <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">real_var</span><span class="op">.</span><span class="nam">assign_sub</span><span class="op">(</span><span class="nam">delta_get_op</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t282" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t283" class="stm run hide_run">  <span class="op">@</span><span class="nam">staticmethod</span><span class="strut">&nbsp;</span></p>
<p id="t284" class="pln">  <span class="com"># pylint: disable=bad-staticmethod-argument,invalid-name</span><span class="strut">&nbsp;</span></p>
<p id="t285" class="stm run hide_run">  <span class="key">def</span> <span class="nam">_TensorConversionFunction</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">as_ref</span><span class="op">=</span><span class="key">False</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t286" class="pln">    <span class="str">"""Utility function for converting a StagedModelVariable to a Tensor."""</span><span class="strut">&nbsp;</span></p>
<p id="t287" class="stm mis">    <span class="key">del</span> <span class="nam">dtype</span><span class="op">,</span> <span class="nam">name</span>  <span class="com"># unused: this function returns the cached ref or value.</span><span class="strut">&nbsp;</span></p>
<p id="t288" class="stm mis">    <span class="key">if</span> <span class="nam">as_ref</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t289" class="stm mis">      <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_ref</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t290" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t291" class="stm mis">      <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_value</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t292" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t293" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t294" class="stm run hide_run"><span class="nam">ops</span><span class="op">.</span><span class="nam">register_tensor_conversion_function</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t295" class="pln">    <span class="nam">StagedModelVariable</span><span class="op">,</span> <span class="nam">StagedModelVariable</span><span class="op">.</span><span class="nam">_TensorConversionFunction</span><span class="op">)</span>  <span class="com"># pylint: disable=protected-access</span><span class="strut">&nbsp;</span></p>
<p id="t296" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t297" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t298" class="stm run hide_run"><span class="key">class</span> <span class="nam">StagedVariableGetter</span><span class="op">(</span><span class="nam">object</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t299" class="pln">  <span class="str">"""A variable getter through staging buffers on devices.</span><span class="strut">&nbsp;</span></p>
<p id="t300" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t301" class="pln"><span class="str">  Instead of a caching device, this getter tracks where the variable is used.</span><span class="strut">&nbsp;</span></p>
<p id="t302" class="pln"><span class="str">  And on each device, it goes through a staging buffer.</span><span class="strut">&nbsp;</span></p>
<p id="t303" class="pln"><span class="str">  """</span><span class="strut">&nbsp;</span></p>
<p id="t304" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t305" class="stm run hide_run">  <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">device_num</span><span class="op">,</span> <span class="nam">devices</span><span class="op">,</span> <span class="nam">cpu_device</span><span class="op">,</span> <span class="nam">variable_mgr</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t306" class="pln">    <span class="str">"""Initializer for StagedVariableGetter.</span><span class="strut">&nbsp;</span></p>
<p id="t307" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t308" class="pln"><span class="str">    Args:</span><span class="strut">&nbsp;</span></p>
<p id="t309" class="pln"><span class="str">      device_num: the current device index.</span><span class="strut">&nbsp;</span></p>
<p id="t310" class="pln"><span class="str">      devices: a list of all the devices to build towers.</span><span class="strut">&nbsp;</span></p>
<p id="t311" class="pln"><span class="str">      cpu_device: a cpu_device for this replica. If None, no cpu-caching is</span><span class="strut">&nbsp;</span></p>
<p id="t312" class="pln"><span class="str">          done.</span><span class="strut">&nbsp;</span></p>
<p id="t313" class="pln"><span class="str">      variable_mgr: the parent variable manager.</span><span class="strut">&nbsp;</span></p>
<p id="t314" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t315" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">device_num</span> <span class="op">=</span> <span class="nam">device_num</span><span class="strut">&nbsp;</span></p>
<p id="t316" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">devices</span> <span class="op">=</span> <span class="nam">devices</span><span class="strut">&nbsp;</span></p>
<p id="t317" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">cpu_device</span> <span class="op">=</span> <span class="nam">cpu_device</span><span class="strut">&nbsp;</span></p>
<p id="t318" class="stm mis">    <span class="nam">self</span><span class="op">.</span><span class="nam">variable_mgr</span> <span class="op">=</span> <span class="nam">variable_mgr</span><span class="strut">&nbsp;</span></p>
<p id="t319" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t320" class="stm run hide_run">  <span class="key">def</span> <span class="nam">__call__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">getter</span><span class="op">,</span> <span class="nam">name</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t321" class="stm mis">    <span class="nam">staging_ops</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">variable_mgr</span><span class="op">.</span><span class="nam">staging_vars_on_devices</span><span class="op">[</span><span class="nam">self</span><span class="op">.</span><span class="nam">device_num</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t322" class="stm mis">    <span class="key">if</span> <span class="nam">name</span> <span class="key">in</span> <span class="nam">staging_ops</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t323" class="stm mis">      <span class="nam">put_op</span><span class="op">,</span> <span class="nam">get_op</span> <span class="op">=</span> <span class="nam">staging_ops</span><span class="op">[</span><span class="nam">name</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t324" class="stm mis">      <span class="key">return</span> <span class="nam">get_op</span><span class="strut">&nbsp;</span></p>
<p id="t325" class="stm mis">    <span class="nam">real_var</span> <span class="op">=</span> <span class="nam">getter</span><span class="op">(</span><span class="nam">name</span><span class="op">,</span> <span class="op">*</span><span class="nam">args</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t326" class="stm mis">    <span class="nam">shape</span> <span class="op">=</span> <span class="nam">kwargs</span><span class="op">[</span><span class="str">'shape'</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t327" class="stm mis">    <span class="nam">dtype</span> <span class="op">=</span> <span class="nam">kwargs</span><span class="op">[</span><span class="str">'dtype'</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t328" class="stm mis">    <span class="nam">trainable</span> <span class="op">=</span> <span class="nam">kwargs</span><span class="op">[</span><span class="str">'trainable'</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t329" class="stm mis">    <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">cpu_device</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t330" class="stm mis">      <span class="key">with</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">device</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">cpu_device</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t331" class="pln">        <span class="com"># This helps copying the weights from the parameter to this server only</span><span class="strut">&nbsp;</span></p>
<p id="t332" class="pln">        <span class="com"># once.</span><span class="strut">&nbsp;</span></p>
<p id="t333" class="stm mis">        <span class="key">if</span> <span class="nam">name</span> <span class="key">in</span> <span class="nam">self</span><span class="op">.</span><span class="nam">variable_mgr</span><span class="op">.</span><span class="nam">staged_vars_on_cpu</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t334" class="stm mis">          <span class="nam">cpu_var</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">variable_mgr</span><span class="op">.</span><span class="nam">staged_vars_on_cpu</span><span class="op">[</span><span class="nam">name</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t335" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t336" class="stm mis">          <span class="nam">cpu_var</span> <span class="op">=</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">identity</span><span class="op">(</span><span class="nam">real_var</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t337" class="stm mis">          <span class="nam">self</span><span class="op">.</span><span class="nam">variable_mgr</span><span class="op">.</span><span class="nam">staged_vars_on_cpu</span><span class="op">[</span><span class="nam">name</span><span class="op">]</span> <span class="op">=</span> <span class="nam">cpu_var</span><span class="strut">&nbsp;</span></p>
<p id="t338" class="stm mis">      <span class="nam">var_to_stage</span> <span class="op">=</span> <span class="nam">cpu_var</span><span class="strut">&nbsp;</span></p>
<p id="t339" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t340" class="stm mis">      <span class="nam">var_to_stage</span> <span class="op">=</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">identity</span><span class="op">(</span><span class="nam">real_var</span><span class="op">)</span>  <span class="com"># de-reference the variable.</span><span class="strut">&nbsp;</span></p>
<p id="t341" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t342" class="stm mis">    <span class="key">with</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">device</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">devices</span><span class="op">[</span><span class="nam">self</span><span class="op">.</span><span class="nam">device_num</span><span class="op">]</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t343" class="stm mis">      <span class="nam">staging_area</span> <span class="op">=</span> <span class="nam">data_flow_ops</span><span class="op">.</span><span class="nam">StagingArea</span><span class="op">(</span><span class="op">[</span><span class="nam">dtype</span><span class="op">]</span><span class="op">,</span> <span class="nam">shapes</span><span class="op">=</span><span class="op">[</span><span class="nam">shape</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t344" class="stm mis">      <span class="nam">put_op</span> <span class="op">=</span> <span class="nam">staging_area</span><span class="op">.</span><span class="nam">put</span><span class="op">(</span><span class="op">[</span><span class="nam">var_to_stage</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t345" class="stm mis">      <span class="nam">get_op</span> <span class="op">=</span> <span class="nam">staging_area</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="op">)</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t346" class="stm mis">      <span class="nam">staging_ops</span><span class="op">[</span><span class="nam">name</span><span class="op">]</span> <span class="op">=</span> <span class="op">(</span><span class="nam">put_op</span><span class="op">,</span> <span class="nam">get_op</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t347" class="stm mis">    <span class="key">if</span> <span class="nam">trainable</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t348" class="pln">      <span class="com"># For trainable variables, they are managed separatedly through</span><span class="strut">&nbsp;</span></p>
<p id="t349" class="pln">      <span class="com"># apply_gradients.</span><span class="strut">&nbsp;</span></p>
<p id="t350" class="stm mis">      <span class="key">return</span> <span class="nam">get_op</span><span class="strut">&nbsp;</span></p>
<p id="t351" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t352" class="pln">      <span class="com"># For other shadow variables, the access is decoupled through a wrapper</span><span class="strut">&nbsp;</span></p>
<p id="t353" class="pln">      <span class="com"># class.</span><span class="strut">&nbsp;</span></p>
<p id="t354" class="stm mis">      <span class="key">return</span> <span class="nam">StagedModelVariable</span><span class="op">(</span><span class="nam">real_var</span><span class="op">,</span> <span class="nam">get_op</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">variable_mgr</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t355" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t356" class="stm run hide_run">  <span class="key">def</span> <span class="nam">trainable_variables_on_device</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">rel_device_num</span><span class="op">,</span> <span class="nam">abs_device_num</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t357" class="pln">                                    <span class="nam">writable</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t358" class="pln">    <span class="str">"""Return the set of trainable variables on the specified device.</span><span class="strut">&nbsp;</span></p>
<p id="t359" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t360" class="pln"><span class="str">    Args:</span><span class="strut">&nbsp;</span></p>
<p id="t361" class="pln"><span class="str">      rel_device_num: local worker device index.</span><span class="strut">&nbsp;</span></p>
<p id="t362" class="pln"><span class="str">      abs_device_num: global graph device index.</span><span class="strut">&nbsp;</span></p>
<p id="t363" class="pln"><span class="str">      writable: whether the returned variables is writable or read-only.</span><span class="strut">&nbsp;</span></p>
<p id="t364" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t365" class="pln"><span class="str">    Returns:</span><span class="strut">&nbsp;</span></p>
<p id="t366" class="pln"><span class="str">      Return the set of trainable variables on the specified device.</span><span class="strut">&nbsp;</span></p>
<p id="t367" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t368" class="stm mis">    <span class="key">del</span> <span class="nam">abs_device_num</span><span class="strut">&nbsp;</span></p>
<p id="t369" class="stm mis">    <span class="nam">params_refs</span> <span class="op">=</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">trainable_variables</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t370" class="stm mis">    <span class="key">if</span> <span class="nam">writable</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t371" class="stm mis">      <span class="key">return</span> <span class="nam">params_refs</span><span class="strut">&nbsp;</span></p>
<p id="t372" class="stm mis">    <span class="nam">params</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t373" class="stm mis">    <span class="key">for</span> <span class="nam">param</span> <span class="key">in</span> <span class="nam">params_refs</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t374" class="stm mis">      <span class="nam">var_name</span> <span class="op">=</span> <span class="nam">param</span><span class="op">.</span><span class="nam">name</span><span class="op">.</span><span class="nam">split</span><span class="op">(</span><span class="str">':'</span><span class="op">)</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t375" class="stm mis">      <span class="nam">_</span><span class="op">,</span> <span class="nam">var_get_op</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">variable_mgr</span><span class="op">.</span><span class="nam">staging_vars_on_devices</span><span class="op">[</span><span class="nam">rel_device_num</span><span class="op">]</span><span class="op">[</span><span class="strut">&nbsp;</span></p>
<p id="t376" class="pln">          <span class="nam">var_name</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t377" class="stm mis">      <span class="nam">params</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">var_get_op</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t378" class="stm mis">    <span class="key">return</span> <span class="nam">params</span><span class="strut">&nbsp;</span></p>
<p id="t379" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t380" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t381" class="stm run hide_run"><span class="key">def</span> <span class="nam">aggregate_gradients_using_copy_with_device_selection</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t382" class="pln">    <span class="nam">benchmark_cnn</span><span class="op">,</span> <span class="nam">tower_grads</span><span class="op">,</span> <span class="nam">use_mean</span><span class="op">,</span> <span class="nam">check_inf_nan</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t383" class="pln">  <span class="str">"""Aggregate gradients, controlling device for the aggregation.</span><span class="strut">&nbsp;</span></p>
<p id="t384" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t385" class="pln"><span class="str">  Args:</span><span class="strut">&nbsp;</span></p>
<p id="t386" class="pln"><span class="str">    benchmark_cnn: benchmark_cnn class.</span><span class="strut">&nbsp;</span></p>
<p id="t387" class="pln"><span class="str">    tower_grads: List of lists of (gradient, variable) tuples. The outer list</span><span class="strut">&nbsp;</span></p>
<p id="t388" class="pln"><span class="str">      is over towers. The inner list is over individual gradients.</span><span class="strut">&nbsp;</span></p>
<p id="t389" class="pln"><span class="str">    use_mean: if True, mean is taken, else sum of gradients is taken.</span><span class="strut">&nbsp;</span></p>
<p id="t390" class="pln"><span class="str">    check_inf_nan: If true, check grads for nans and infs.</span><span class="strut">&nbsp;</span></p>
<p id="t391" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t392" class="pln"><span class="str">  Returns:</span><span class="strut">&nbsp;</span></p>
<p id="t393" class="pln"><span class="str">    The tuple ([(average_gradient, variable),], has_nan_or_inf) where the</span><span class="strut">&nbsp;</span></p>
<p id="t394" class="pln"><span class="str">      gradient has been averaged across all towers. The variable is chosen from</span><span class="strut">&nbsp;</span></p>
<p id="t395" class="pln"><span class="str">      the first tower. The has_nan_or_inf indicates the grads has nan or inf.</span><span class="strut">&nbsp;</span></p>
<p id="t396" class="pln"><span class="str">  """</span><span class="strut">&nbsp;</span></p>
<p id="t397" class="stm mis">  <span class="key">if</span> <span class="nam">benchmark_cnn</span><span class="op">.</span><span class="nam">local_parameter_device_flag</span> <span class="op">==</span> <span class="str">'gpu'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t398" class="stm mis">    <span class="nam">avail_devices</span> <span class="op">=</span> <span class="nam">benchmark_cnn</span><span class="op">.</span><span class="nam">raw_devices</span><span class="strut">&nbsp;</span></p>
<p id="t399" class="pln">  <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t400" class="stm mis">    <span class="nam">avail_devices</span> <span class="op">=</span> <span class="op">[</span><span class="nam">benchmark_cnn</span><span class="op">.</span><span class="nam">param_server_device</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t401" class="stm mis">  <span class="nam">agg_grads</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t402" class="stm mis">  <span class="nam">has_nan_or_inf_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t403" class="stm mis">  <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">single_grads</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">zip</span><span class="op">(</span><span class="op">*</span><span class="nam">tower_grads</span><span class="op">)</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t404" class="stm mis">    <span class="key">with</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">device</span><span class="op">(</span><span class="nam">avail_devices</span><span class="op">[</span><span class="nam">i</span> <span class="op">%</span> <span class="nam">len</span><span class="op">(</span><span class="nam">avail_devices</span><span class="op">)</span><span class="op">]</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t405" class="stm mis">      <span class="nam">grad_and_var</span><span class="op">,</span> <span class="nam">has_nan_or_inf</span> <span class="op">=</span> <span class="nam">aggregate_single_gradient_using_copy</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t406" class="pln">          <span class="nam">single_grads</span><span class="op">,</span> <span class="nam">use_mean</span><span class="op">,</span> <span class="nam">check_inf_nan</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t407" class="stm mis">      <span class="nam">agg_grads</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">grad_and_var</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t408" class="stm mis">      <span class="nam">has_nan_or_inf_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">has_nan_or_inf</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t409" class="stm mis">  <span class="key">if</span> <span class="nam">check_inf_nan</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t410" class="stm mis">    <span class="key">return</span> <span class="nam">agg_grads</span><span class="op">,</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">reduce_any</span><span class="op">(</span><span class="nam">has_nan_or_inf_list</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t411" class="pln">  <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t412" class="stm mis">    <span class="key">return</span> <span class="nam">agg_grads</span><span class="op">,</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t413" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t414" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t415" class="stm run hide_run"><span class="key">def</span> <span class="nam">aggregate_gradients_using_copy_with_variable_colocation</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t416" class="pln">    <span class="nam">tower_grads</span><span class="op">,</span> <span class="nam">use_mean</span><span class="op">,</span> <span class="nam">check_inf_nan</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t417" class="pln">  <span class="str">"""Aggregate gradients, colocating computation with the gradient's variable.</span><span class="strut">&nbsp;</span></p>
<p id="t418" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t419" class="pln"><span class="str">  Args:</span><span class="strut">&nbsp;</span></p>
<p id="t420" class="pln"><span class="str">    tower_grads: List of lists of (gradient, variable) tuples. The outer list</span><span class="strut">&nbsp;</span></p>
<p id="t421" class="pln"><span class="str">      is over towers. The inner list is over individual gradients. All variables</span><span class="strut">&nbsp;</span></p>
<p id="t422" class="pln"><span class="str">      of the same gradient across towers must be the same (that is,</span><span class="strut">&nbsp;</span></p>
<p id="t423" class="pln"><span class="str">      tower_grads[x][a][1] == tower_grads[y][a][1] for all indices x, y, and a)</span><span class="strut">&nbsp;</span></p>
<p id="t424" class="pln"><span class="str">    use_mean: if True, mean is taken, else sum of gradients is taken.</span><span class="strut">&nbsp;</span></p>
<p id="t425" class="pln"><span class="str">    check_inf_nan: If true, check grads for nans and infs.</span><span class="strut">&nbsp;</span></p>
<p id="t426" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t427" class="pln"><span class="str">  Returns:</span><span class="strut">&nbsp;</span></p>
<p id="t428" class="pln"><span class="str">    The tuple ([(average_gradient, variable),], has_nan_or_inf) where the</span><span class="strut">&nbsp;</span></p>
<p id="t429" class="pln"><span class="str">      gradient has been averaged across all towers. The variable is chosen from</span><span class="strut">&nbsp;</span></p>
<p id="t430" class="pln"><span class="str">      the first tower. The has_nan_or_inf indicates the grads has nan or inf.</span><span class="strut">&nbsp;</span></p>
<p id="t431" class="pln"><span class="str">  """</span><span class="strut">&nbsp;</span></p>
<p id="t432" class="stm run hide_run">  <span class="nam">agg_grads</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t433" class="stm run hide_run">  <span class="nam">has_nan_or_inf_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t434" class="stm run hide_run">  <span class="key">for</span> <span class="nam">single_grads</span> <span class="key">in</span> <span class="nam">zip</span><span class="op">(</span><span class="op">*</span><span class="nam">tower_grads</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t435" class="pln">    <span class="com"># Note that each single_grads looks like the following:</span><span class="strut">&nbsp;</span></p>
<p id="t436" class="pln">    <span class="com">#   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))</span><span class="strut">&nbsp;</span></p>
<p id="t437" class="stm run hide_run">    <span class="nam">var</span> <span class="op">=</span> <span class="nam">single_grads</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t438" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t439" class="stm run hide_run">    <span class="key">for</span> <span class="nam">_</span><span class="op">,</span> <span class="nam">v</span> <span class="key">in</span> <span class="nam">single_grads</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t440" class="stm run hide_run">      <span class="key">assert</span> <span class="nam">v</span> <span class="op">==</span> <span class="nam">var</span><span class="strut">&nbsp;</span></p>
<p id="t441" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t442" class="stm run hide_run">    <span class="key">with</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">device</span><span class="op">(</span><span class="nam">var</span><span class="op">.</span><span class="nam">device</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t443" class="stm run hide_run">      <span class="nam">grad_and_var</span><span class="op">,</span> <span class="nam">has_nan_or_inf</span> <span class="op">=</span> <span class="nam">aggregate_single_gradient_using_copy</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t444" class="pln">          <span class="nam">single_grads</span><span class="op">,</span> <span class="nam">use_mean</span><span class="op">,</span> <span class="nam">check_inf_nan</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t445" class="stm run hide_run">      <span class="nam">agg_grads</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">grad_and_var</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t446" class="stm run hide_run">      <span class="nam">has_nan_or_inf_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">has_nan_or_inf</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t447" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t448" class="stm run hide_run">  <span class="key">if</span> <span class="nam">check_inf_nan</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t449" class="stm mis">    <span class="key">return</span> <span class="nam">agg_grads</span><span class="op">,</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">reduce_any</span><span class="op">(</span><span class="nam">has_nan_or_inf_list</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t450" class="pln">  <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t451" class="stm run hide_run">    <span class="key">return</span> <span class="nam">agg_grads</span><span class="op">,</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t452" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t453" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t454" class="stm run hide_run"><span class="key">def</span> <span class="nam">aggregate_gradients_using_copy</span><span class="op">(</span><span class="nam">tower_grads</span><span class="op">,</span> <span class="nam">use_mean</span><span class="op">,</span> <span class="nam">check_inf_nan</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t455" class="pln">  <span class="str">"""Calculate the average gradient for each shared variable across all towers.</span><span class="strut">&nbsp;</span></p>
<p id="t456" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t457" class="pln"><span class="str">  Note that this function provides a synchronization point across all towers.</span><span class="strut">&nbsp;</span></p>
<p id="t458" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t459" class="pln"><span class="str">  Args:</span><span class="strut">&nbsp;</span></p>
<p id="t460" class="pln"><span class="str">    tower_grads: List of lists of (gradient, variable) tuples. The outer list</span><span class="strut">&nbsp;</span></p>
<p id="t461" class="pln"><span class="str">      is over towers. The inner list is over individual gradients.</span><span class="strut">&nbsp;</span></p>
<p id="t462" class="pln"><span class="str">    use_mean: if True, mean is taken, else sum of gradients is taken.</span><span class="strut">&nbsp;</span></p>
<p id="t463" class="pln"><span class="str">    check_inf_nan: check grads for nans and infs.</span><span class="strut">&nbsp;</span></p>
<p id="t464" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t465" class="pln"><span class="str">  Returns:</span><span class="strut">&nbsp;</span></p>
<p id="t466" class="pln"><span class="str">    The tuple ([(average_gradient, variable),], has_nan_or_inf) where the</span><span class="strut">&nbsp;</span></p>
<p id="t467" class="pln"><span class="str">      gradient has been averaged across all towers. The variable is chosen from</span><span class="strut">&nbsp;</span></p>
<p id="t468" class="pln"><span class="str">      the first tower. The has_nan_or_inf indicates the grads has nan or inf.</span><span class="strut">&nbsp;</span></p>
<p id="t469" class="pln"><span class="str">  """</span><span class="strut">&nbsp;</span></p>
<p id="t470" class="stm mis">  <span class="nam">agg_grads</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t471" class="stm mis">  <span class="nam">has_nan_or_inf_list</span> <span class="op">=</span> <span class="op">[</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t472" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t473" class="stm mis">  <span class="key">for</span> <span class="nam">single_grads</span> <span class="key">in</span> <span class="nam">zip</span><span class="op">(</span><span class="op">*</span><span class="nam">tower_grads</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t474" class="stm mis">    <span class="nam">grad_and_var</span><span class="op">,</span> <span class="nam">has_nan_or_inf</span> <span class="op">=</span> <span class="nam">aggregate_single_gradient_using_copy</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t475" class="pln">        <span class="nam">single_grads</span><span class="op">,</span> <span class="nam">use_mean</span><span class="op">,</span> <span class="nam">check_inf_nan</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t476" class="stm mis">    <span class="nam">agg_grads</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">grad_and_var</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t477" class="stm mis">    <span class="nam">has_nan_or_inf_list</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="nam">has_nan_or_inf</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t478" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t479" class="stm mis">  <span class="key">if</span> <span class="nam">check_inf_nan</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t480" class="stm mis">    <span class="key">return</span> <span class="nam">agg_grads</span><span class="op">,</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">reduce_any</span><span class="op">(</span><span class="nam">has_nan_or_inf_list</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t481" class="pln">  <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t482" class="stm mis">    <span class="key">return</span> <span class="nam">agg_grads</span><span class="op">,</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t483" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t484" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t485" class="stm run hide_run"><span class="key">def</span> <span class="nam">aggregate_single_gradient_using_copy</span><span class="op">(</span><span class="nam">grad_and_vars</span><span class="op">,</span> <span class="nam">use_mean</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t486" class="pln">                                         <span class="nam">check_inf_nan</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t487" class="pln">  <span class="str">"""Calculate the average gradient for a shared variable across all towers.</span><span class="strut">&nbsp;</span></p>
<p id="t488" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t489" class="pln"><span class="str">  Note that this function provides a synchronization point across all towers.</span><span class="strut">&nbsp;</span></p>
<p id="t490" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t491" class="pln"><span class="str">  Args:</span><span class="strut">&nbsp;</span></p>
<p id="t492" class="pln"><span class="str">    grad_and_vars: A list or tuple of (gradient, variable) tuples. Each</span><span class="strut">&nbsp;</span></p>
<p id="t493" class="pln"><span class="str">      (gradient, variable) pair within the outer list represents the gradient</span><span class="strut">&nbsp;</span></p>
<p id="t494" class="pln"><span class="str">      of the variable calculated for a single tower, and the number of pairs</span><span class="strut">&nbsp;</span></p>
<p id="t495" class="pln"><span class="str">      equals the number of towers.</span><span class="strut">&nbsp;</span></p>
<p id="t496" class="pln"><span class="str">    use_mean: if True, mean is taken, else sum of gradients is taken.</span><span class="strut">&nbsp;</span></p>
<p id="t497" class="pln"><span class="str">    check_inf_nan: check grads for nans and infs.</span><span class="strut">&nbsp;</span></p>
<p id="t498" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t499" class="pln"><span class="str">  Returns:</span><span class="strut">&nbsp;</span></p>
<p id="t500" class="pln"><span class="str">    The tuple ([(average_gradient, variable),], has_nan_or_inf) where the</span><span class="strut">&nbsp;</span></p>
<p id="t501" class="pln"><span class="str">      gradient has been averaged across all towers. The variable is chosen from</span><span class="strut">&nbsp;</span></p>
<p id="t502" class="pln"><span class="str">      the first tower. The has_nan_or_inf indicates the grads has nan or inf.</span><span class="strut">&nbsp;</span></p>
<p id="t503" class="pln"><span class="str">  """</span><span class="strut">&nbsp;</span></p>
<p id="t504" class="stm run hide_run">  <span class="nam">grads</span> <span class="op">=</span> <span class="op">[</span><span class="nam">g</span> <span class="key">for</span> <span class="nam">g</span><span class="op">,</span> <span class="nam">_</span> <span class="key">in</span> <span class="nam">grad_and_vars</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t505" class="stm run hide_run">  <span class="nam">grad</span> <span class="op">=</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">add_n</span><span class="op">(</span><span class="nam">grads</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t506" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t507" class="stm run hide_run">  <span class="key">if</span> <span class="nam">use_mean</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">grads</span><span class="op">)</span> <span class="op">></span> <span class="num">1</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t508" class="stm run hide_run">    <span class="nam">grad</span> <span class="op">=</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">multiply</span><span class="op">(</span><span class="nam">grad</span><span class="op">,</span> <span class="num">1.0</span> <span class="op">/</span> <span class="nam">len</span><span class="op">(</span><span class="nam">grads</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t509" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t510" class="stm run hide_run">  <span class="nam">v</span> <span class="op">=</span> <span class="nam">grad_and_vars</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t511" class="stm run hide_run">  <span class="key">if</span> <span class="nam">check_inf_nan</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t512" class="stm mis">    <span class="nam">has_nan_or_inf</span> <span class="op">=</span> <span class="nam">tf</span><span class="op">.</span><span class="nam">logical_not</span><span class="op">(</span><span class="nam">tf</span><span class="op">.</span><span class="nam">reduce_all</span><span class="op">(</span><span class="nam">tf</span><span class="op">.</span><span class="nam">is_finite</span><span class="op">(</span><span class="nam">grads</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t513" class="stm mis">    <span class="key">return</span> <span class="op">(</span><span class="nam">grad</span><span class="op">,</span> <span class="nam">v</span><span class="op">)</span><span class="op">,</span> <span class="nam">has_nan_or_inf</span><span class="strut">&nbsp;</span></p>
<p id="t514" class="pln">  <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t515" class="stm run hide_run">    <span class="key">return</span> <span class="op">(</span><span class="nam">grad</span><span class="op">,</span> <span class="nam">v</span><span class="op">)</span><span class="op">,</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>

            </td>
        </tr>
    </table>
</div>

<div id="footer">
    <div class="content">
        <p>
            <a class="nav" href="index.html">&#xab; index</a> &nbsp; &nbsp; <a class="nav" href="https://coverage.readthedocs.io">coverage.py v4.5.4</a>,
            created at 2019-08-05 16:37
        </p>
    </div>
</div>

</body>
</html>
